# ğŸ—ï¸ Arquitetura e Componentes Solview

## ğŸ¯ VisÃ£o Geral da Arquitetura

O **Solview** implementa uma arquitetura de observabilidade distribuÃ­da seguindo as melhores prÃ¡ticas da **OpenTelemetry** e **CNCF (Cloud Native Computing Foundation)**.

```mermaid
graph TB
    subgraph "AplicaÃ§Ã£o"
        App[FastAPI Application]
        Solview[Solview Library]
        App --> Solview
    end
    
    subgraph "Coleta (Collection Layer)"
        OTel[OpenTelemetry Collector]
        Solview --> |OTLP gRPC/HTTP| OTel
    end
    
    subgraph "Armazenamento (Storage Layer)"
        Prometheus[Prometheus<br/>ğŸ“Š Metrics]
        Loki[Loki<br/>ğŸ“ Logs] 
        Tempo[Tempo<br/>ğŸ” Traces]
        
        OTel --> |Remote Write| Prometheus
        OTel --> |Loki API| Loki
        OTel --> |OTLP| Tempo
    end
    
    subgraph "VisualizaÃ§Ã£o (Visualization Layer)"
        Grafana[Grafana<br/>ğŸ“Š Dashboards]
        ServiceGraph[Service Graph<br/>ğŸ—ºï¸ Topology]
        
        Prometheus --> Grafana
        Loki --> Grafana
        Tempo --> Grafana
        Tempo --> ServiceGraph
    end
    
    subgraph "CorrelaÃ§Ã£o (Correlation Layer)"
        TraceToMetrics[Trace â†’ Metrics]
        TraceToLogs[Trace â†’ Logs]
        MetricsToTraces[Metrics â†’ Traces]
        
        Grafana --> TraceToMetrics
        Grafana --> TraceToLogs
        Grafana --> MetricsToTraces
    end
```

---

## ğŸ”§ Componentes Principais

### ğŸ“š **Solview Library**

#### **Estrutura do MÃ³dulo**

```
solview/
â”œâ”€â”€ __init__.py              # API principal
â”œâ”€â”€ settings.py              # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ version.py               # Controle de versÃ£o
â”œâ”€â”€ common/                  # UtilitÃ¡rios compartilhados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ masking.py          # Masking de dados sensÃ­veis
â”œâ”€â”€ metrics/                 # Sistema de mÃ©tricas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py             # MÃ©tricas core (HTTP, sistema)
â”‚   â””â”€â”€ exporters.py        # Exportadores (Prometheus)
â”œâ”€â”€ solview_logging/         # Sistema de logs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py             # Setup e configuraÃ§Ã£o
â”‚   â”œâ”€â”€ settings.py         # ConfiguraÃ§Ãµes especÃ­ficas
â”‚   â””â”€â”€ sinks.py            # Destinos de logs
â”œâ”€â”€ tracing/                 # Sistema de tracing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py             # Setup OpenTelemetry
â”‚   â””â”€â”€ propagators.py      # PropagaÃ§Ã£o de contexto
â””â”€â”€ security/                # MÃ³dulo de masking
    â”œâ”€â”€ __init__.py         # Exporta somente masking
    â””â”€â”€ masking.py          # Masking avanÃ§ado
```

#### **API Principal**

```python
# solview/__init__.py
from .settings import SolviewSettings
from .solview_logging import setup_logger, get_logger
from .tracing import setup_tracer, get_tracer
from .metrics import get_metrics_registry
from .security import MaskingRule, enhanced_masking

__version__ = "2.0.1"

# API pÃºblica simplificada
__all__ = [
    "SolviewSettings",
    "setup_logger",
    "get_logger", 
    "setup_tracer",
    "get_tracer",
    "get_metrics_registry",
    "MaskingRule",
    "enhanced_masking",
]
```

---

## ğŸ“Š Sistema de MÃ©tricas

### **Arquitetura de MÃ©tricas**

```mermaid
graph LR
    subgraph "AplicaÃ§Ã£o"
        Request[HTTP Request]
        Middleware[Solview Middleware]
        Handler[Route Handler]
        
        Request --> Middleware
        Middleware --> Handler
        Handler --> Middleware
    end
    
    subgraph "MÃ©tricas Core"
        HTTPMetrics[HTTP Metrics]
        SystemMetrics[System Metrics]
        CustomMetrics[Custom Metrics]
        
        Middleware --> HTTPMetrics
        Middleware --> SystemMetrics
        Handler --> CustomMetrics
    end
    
    subgraph "Registry"
        PrometheusRegistry[Prometheus Registry]
        
        HTTPMetrics --> PrometheusRegistry
        SystemMetrics --> PrometheusRegistry
        CustomMetrics --> PrometheusRegistry
    end
    
    subgraph "Export"
        MetricsEndpoint[/metrics Endpoint]
        RemoteWrite[Remote Write]
        
        PrometheusRegistry --> MetricsEndpoint
        PrometheusRegistry --> RemoteWrite
    end
```

### **MÃ©tricas AutomÃ¡ticas**

```python
# solview/metrics/core.py
from prometheus_client import Counter, Histogram, Gauge, Info

class SolviewMetrics:
    def __init__(self, service_name: str, registry):
        self.registry = registry
        
        # HTTP Metrics (compatÃ­veis com OpenTelemetry)
        self.http_requests_total = Counter(
            'http_requests_total',
            'Total HTTP requests',
            ['method', 'endpoint', 'status_code', 'service_name'],
            registry=registry
        )
        
        self.http_request_duration_seconds = Histogram(
            'http_request_duration_seconds',
            'HTTP request duration',
            ['method', 'endpoint', 'service_name'],
            buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
            registry=registry
        )
        
        self.http_responses_total = Counter(
            'http_responses_total',
            'Total HTTP responses',
            ['method', 'endpoint', 'status_code', 'service_name'],
            registry=registry
        )
        
        # System Metrics
        self.process_cpu_usage = Gauge(
            'process_cpu_usage_percent',
            'Process CPU usage',
            ['service_name'],
            registry=registry
        )
        
        self.process_memory_usage = Gauge(
            'process_memory_usage_bytes',
            'Process memory usage',
            ['service_name'],
            registry=registry
        )
        
        # Service Info
        self.service_info = Info(
            'service_info',
            'Service information',
            registry=registry
        )
        
        # Inicializar info
        self.service_info.info({
            'name': service_name,
            'version': get_version(),
            'framework': 'fastapi',
            'instrumentation': 'solview'
        })
```

---

## ğŸ“ Sistema de Logging

### **Arquitetura de Logs**

```mermaid
graph TB
    subgraph "AplicaÃ§Ã£o"
        Code[Application Code]
        Logger[Solview Logger]
        Code --> Logger
    end
    
    subgraph "Processing"
        Formatter[JSON Formatter]
        Enricher[Context Enricher]
        Masker[Data Masker]
        
        Logger --> Formatter
        Formatter --> Enricher
        Enricher --> Masker
    end
    
    subgraph "Sinks"
        Console[Console Output]
        File[File Output]
        OTLP[OTLP Exporter]
        
        Masker --> Console
        Masker --> File
        Masker --> OTLP
    end
    
    subgraph "Storage"
        Loki[Loki]
        OTLP --> Loki
    end
```

### **Estrutura de Log**

```json
{
  "timestamp": "2024-01-20T15:30:45.123Z",
  "level": "INFO",
  "message": "User login successful",
  "service_name": "auth-service",
  "service_version": "1.2.3",
  "environment": "production",
  "trace_id": "1234567890abcdef1234567890abcdef",
  "span_id": "1234567890abcdef",
  "user_id": "user_123",
  "endpoint": "/api/auth/login",
  "method": "POST",
  "status_code": 200,
  "duration_ms": 156,
  "ip_address": "192.168.1.100",
  "user_agent": "Mozilla/5.0...",
  "custom_field": "custom_value"
}
```

### **Logger Configuration**

```python
# solview/solview_logging/core.py
import structlog
from solview import get_logger
loguru_logger = get_logger(__name__)

def setup_logger(settings: SolviewSettings):
    """Setup structured logging with OpenTelemetry integration"""
    
    # Configurar processadores structlog
    processors = [
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        # Adicionar trace context automaticamente
        add_trace_context,
        # Masking de dados sensÃ­veis
        mask_sensitive_data if settings.enable_data_masking else lambda _, __, event_dict: event_dict,
        # JSON output
        structlog.processors.JSONRenderer()
    ]
    
    structlog.configure(
        processors=processors,
        wrapper_class=structlog.stdlib.BoundLogger,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
```

---

## ğŸ” Sistema de Tracing

### **Arquitetura de Tracing**

```mermaid
graph TB
    subgraph "InstrumentaÃ§Ã£o"
        AutoInstr[Auto Instrumentation]
        ManualInstr[Manual Instrumentation]
        
        subgraph "Auto Instrumentation"
            FastAPIInstr[FastAPI]
            HTTPXInstr[HTTPX]
            SQLAlchemyInstr[SQLAlchemy]
            PsycopgInstr[Psycopg]
        end
    end
    
    subgraph "Tracing Pipeline"
        SpanProcessor[Span Processor]
        Sampler[Sampler]
        ResourceDetector[Resource Detector]
        
        AutoInstr --> SpanProcessor
        ManualInstr --> SpanProcessor
        SpanProcessor --> Sampler
        Sampler --> ResourceDetector
    end
    
    subgraph "Export"
        BatchExporter[Batch Exporter]
        OTLPExporter[OTLP Exporter]
        
        ResourceDetector --> BatchExporter
        BatchExporter --> OTLPExporter
    end
    
    subgraph "Backend"
        OTelCollector[OTel Collector]
        Tempo[Tempo]
        
        OTLPExporter --> OTelCollector
        OTelCollector --> Tempo
    end
```

### **Setup de Tracing**

```python
# solview/tracing/core.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.sdk.resources import Resource

def setup_tracer(settings: SolviewSettings, app: FastAPI = None):
    """Setup OpenTelemetry tracing"""
    
    # Resource com informaÃ§Ãµes do serviÃ§o
    resource = Resource.create({
        "service.name": settings.service_name,
        "service.version": settings.service_version,
        "service.namespace": settings.service_namespace,
        "deployment.environment": settings.environment,
        "solview.version": __version__,
        "solview.stack": "fastapi+solview"
    })
    
    # TracerProvider
    provider = TracerProvider(
        resource=resource,
        sampler=trace.sampling.TraceIdRatioBased(settings.trace_sampling_rate)
    )
    
    # OTLP Exporter
    otlp_exporter = OTLPSpanExporter(
        endpoint=settings.otlp_endpoint,
        insecure=not settings.otlp_exporter_http_encrypted
    )
    
    # Batch Processor
    span_processor = BatchSpanProcessor(
        otlp_exporter,
        max_queue_size=2048,
        max_export_batch_size=512,
        export_timeout_millis=30000
    )
    
    provider.add_span_processor(span_processor)
    trace.set_tracer_provider(provider)
    
    # Auto-instrumentaÃ§Ã£o
    if app:
        FastAPIInstrumentor.instrument_app(
            app,
            excluded_urls=settings.excluded_urls,
            tracer_provider=provider
        )
    
    return trace.get_tracer(__name__)
```

---

## ğŸ—„ï¸ Stack de Armazenamento

### **Prometheus (MÃ©tricas)**

#### **ConfiguraÃ§Ã£o**
```yaml
# docker/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'solview-demo-app'
    static_configs:
      - targets: ['solview-demo:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s
    
  - job_name: 'backend-processor'
    static_configs:
      - targets: ['backend-processor:8001']
    metrics_path: '/metrics'
    scrape_interval: 5s

# Remote write para receber mÃ©tricas do Tempo
remote_write:
  - url: http://localhost:9090/api/v1/write
```

#### **Alerting Rules**
```yaml
# docker/prometheus/rules/solview-alerts.yml
groups:
  - name: solview.rules
    rules:
      - alert: HighErrorRate
        expr: rate(http_responses_total{status_code=~"5.."}[5m]) / rate(http_responses_total[5m]) > 0.05
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.service_name }}"
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.service_name }}"
```

### **Loki (Logs)**

#### **ConfiguraÃ§Ã£o**
```yaml
# docker/loki/loki.yml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    cache_location: /loki/boltdb-shipper-cache
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

limits_config:
  reject_old_samples: true
  reject_old_samples_max_age: 168h
  ingestion_rate_mb: 16
  ingestion_burst_size_mb: 32
```

### **Tempo (Traces)**

#### **ConfiguraÃ§Ã£o com Service Graph**
```yaml
# docker/tempo/tempo.yml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

ingester:
  max_block_duration: 5m

compactor:
  compaction:
    block_retention: 1h

metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: docker-compose
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
  processor:
    service_graphs:
      dimensions:
        - service.name
        - service.namespace
        - service.version
    span_metrics:
      dimensions:
        - service.name
        - service.namespace
        - http.method
        - http.status_code

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces

overrides:
  defaults:
    metrics_generator:
      processors: ['service-graphs', 'span-metrics']
```

---

## ğŸ“Š Sistema de CorrelaÃ§Ã£o

### **Trace â†’ Metrics**

```yaml
# docker/grafana/datasources/datasources.yml
tracesToMetrics:
  datasourceUid: prometheus-uid
  spanStartTimeShift: '-2m'
  spanEndTimeShift: '2m'
  tags:
    - { key: 'service.name', value: 'service_name' }
    - { key: 'app', value: 'app' }
  queries:
    - name: 'Request Rate'
      query: 'rate(http_requests_total{service_name="${__span.tags["service.name"]}"}[5m])'
    - name: 'Error Rate'
      query: 'rate(http_responses_total{service_name="${__span.tags["service.name"]}",status_code=~"4..|5.."}[5m]) / rate(http_responses_total{service_name="${__span.tags["service.name"]}"}[5m]) * 100'
    - name: 'Latency P95'
      query: 'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{service_name="${__span.tags["service.name"]}"}[5m]))'
```

### **Trace â†’ Logs**

```yaml
tracesToLogs:
  datasourceUid: loki-uid
  tags: ['service.name', 'app']
  mappedTags:
    - { key: 'service.name', value: 'service_name' }
    - { key: 'app', value: 'app' }
  mapTagNamesEnabled: true
  spanStartTimeShift: '-5m'
  spanEndTimeShift: '5m'
  filterByTraceID: true
  filterBySpanID: false
  customQuery: true
  query: '{app="${__trace.tags.service.name}"} OR {service_name="${__trace.tags.service.name}"} | json | labels.trace_id = "${__trace.traceId}"'
```

---

## ğŸ”’ Componentes de SeguranÃ§a

### **Data Masking**

```python
# solview/security/masking.py
import re
from typing import Dict, Any, List

class DataMasker:
    def __init__(self, config: MaskingConfig):
        self.sensitive_fields = config.sensitive_fields
        self.pii_fields = config.pii_fields
        self.custom_patterns = config.custom_patterns
    
    def mask_dict(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Mask sensitive data in dictionary"""
        if not isinstance(data, dict):
            return data
        
        masked = {}
        for key, value in data.items():
            if self._is_sensitive_field(key):
                masked[key] = self._mask_value(value, key)
            elif isinstance(value, dict):
                masked[key] = self.mask_dict(value)
            elif isinstance(value, list):
                masked[key] = [self.mask_dict(item) if isinstance(item, dict) else item for item in value]
            else:
                masked[key] = self._apply_pattern_masking(str(value))
        
        return masked
    
    def _mask_value(self, value: Any, field_name: str) -> str:
        """Mask specific field value"""
        if field_name in ['password', 'secret', 'token', 'key']:
            return '***'
        elif field_name in ['email']:
            return self._mask_email(str(value))
        elif field_name in ['cpf']:
            return self._mask_cpf(str(value))
        elif field_name in ['credit_card']:
            return self._mask_credit_card(str(value))
        else:
            return '***'
```

---

## ğŸ“ˆ Performance e Scaling

### **ConfiguraÃ§Ãµes de Performance**

```python
# solview/settings.py
class SolviewSettings(BaseSettings):
    # Performance
    trace_sampling_rate: float = Field(0.1, ge=0.0, le=1.0)
    max_span_attributes: int = Field(128, ge=0)
    max_span_events: int = Field(128, ge=0)
    max_span_links: int = Field(128, ge=0)
    
    # Batching
    span_export_batch_size: int = Field(512, ge=1)
    span_export_timeout_ms: int = Field(30000, ge=1000)
    span_export_max_queue_size: int = Field(2048, ge=1)
    
    # Metrics
    metrics_export_interval_ms: int = Field(60000, ge=1000)
    metrics_export_timeout_ms: int = Field(30000, ge=1000)
```

### **Benchmarks**

| MÃ©trica | Valor | ObservaÃ§Ã£o |
|---------|-------|------------|
| **Overhead CPU** | < 5% | Em produÃ§Ã£o com sampling 0.1 |
| **Overhead MemÃ³ria** | < 50MB | Por instÃ¢ncia |
| **LatÃªncia Adicional** | < 1ms | P95 para instrumentaÃ§Ã£o |
| **Throughput** | 10k+ RPS | Testado em produÃ§Ã£o |

---

## ğŸ”§ ConfiguraÃ§Ã£o e Deployment

### **VariÃ¡veis de Ambiente**

```bash
# ServiÃ§o
SOLVIEW_SERVICE_NAME=minha-api
SOLVIEW_SERVICE_VERSION=1.0.0
SOLVIEW_ENVIRONMENT=production

# OpenTelemetry
SOLVIEW_OTLP_ENDPOINT=http://otel-collector:4317
SOLVIEW_TRACE_SAMPLING_RATE=0.1

# Logs
SOLVIEW_LOG_LEVEL=INFO
SOLVIEW_LOG_FORMAT=json

# MÃ©tricas
SOLVIEW_METRICS_ENABLED=true
SOLVIEW_METRICS_PORT=8000

# SeguranÃ§a
SOLVIEW_ENABLE_DATA_MASKING=true
```

### **Docker Compose Stack**

```yaml
# docker-compose.yml
version: '3.8'

services:
  # AplicaÃ§Ã£o
  app:
    build: .
    environment:
      - SOLVIEW_SERVICE_NAME=minha-api
      - SOLVIEW_OTLP_ENDPOINT=http://otel-collector:4317
    depends_on:
      - otel-collector
  
  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./docker/otel-collector/otel-collector.yml:/etc/otel-collector-config.yaml
    depends_on:
      - prometheus
      - loki
      - tempo
  
  # Storage Layer
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./docker/prometheus:/etc/prometheus
  
  loki:
    image: grafana/loki:latest
    volumes:
      - ./docker/loki:/etc/loki
  
  tempo:
    image: grafana/tempo:latest
    volumes:
      - ./docker/tempo:/etc/tempo
  
  # Visualization
  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./docker/grafana:/etc/grafana/provisioning
```

---

<div align="center">

**ğŸ—ï¸ Arquitetura robusta para observabilidade de classe empresarial**

[ğŸ  Home](../README.md) | [ğŸ“š Docs](README.md) | [ğŸ“‹ InstrumentaÃ§Ã£o](instrumentation-guide.md)

</div>
